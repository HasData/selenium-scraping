![Python](https://img.shields.io/badge/python-3.7+-blue)
![Node.js](https://img.shields.io/badge/node.js-18+-green)
![Selenium](https://img.shields.io/badge/selenium-4.36+-blueviolet)

# Selenium Scraping Examples (Python & Node.js)
[![HasData_bannner](banner.png)](https://hasdata.com/)

This repo contains working **Selenium examples** for web scraping in **Python** and **Node.js**.  
It covers everything from driver setup, navigation, waits, element extraction, downloads, network/proxy management, to scaling strategies (Grid) and async scraping.

## Table of Contents

1. [Requirements](#requirements)  
2. [Project Structure](#project-structure)  
3. [Python Selenium Examples](#python-selenium-examples)  
4. [Node.js Selenium Examples](#nodejs-selenium-examples)   
5. [Notes](#notes)
6. [More Resources](#-more-resources)


## Requirements

- **Python 3.8+**  
- **pip**  
- **Node.js 18+**  
- **npm** or **yarn**


## Requirements

- **Node.js 18+**
- **npm** or **yarn**


## Project Structure

```
selenium-scraping/
â”‚
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ 01_install_selenium.md
â”‚   â”œâ”€â”€ 02_driver_initialization.py
â”‚   â”œâ”€â”€ 03_context_manager.py
â”‚   â”œâ”€â”€ 04_options_headless.py
â”‚   â”œâ”€â”€ 05_prefs_and_cdp.py
â”‚   â”œâ”€â”€ 06_navigation.py
â”‚   â”œâ”€â”€ 07_locators_and_find.py
â”‚   â”œâ”€â”€ 08_shadow_dom.py
â”‚   â”œâ”€â”€ 09_data_extraction.py
â”‚   â”œâ”€â”€ 10_lists_and_tables.py
â”‚   â”œâ”€â”€ 11_export_csv_json.py
â”‚   â”œâ”€â”€ 12_waits_and_sync.py
â”‚   â”œâ”€â”€ 13_stale_handling.py
â”‚   â”œâ”€â”€ 14_interactions.py
â”‚   â”œâ”€â”€ 15_scrolling.py
â”‚   â”œâ”€â”€ 16_tabs_frames_alerts.py
â”‚   â”œâ”€â”€ 17_sessions_and_auth.py
â”‚   â”œâ”€â”€ 18_downloads_and_monitoring.py
â”‚   â”œâ”€â”€ 19_debugging_and_logging.py
â”‚   â”œâ”€â”€ 20_network_and_proxy.py
â”‚   â”œâ”€â”€ 21_grid_examples.py
â”‚   â”œâ”€â”€ 22_scrapy_integration.py
â”‚   â””â”€â”€ 23_hasdata_async_example.py
â”‚
â”œâ”€â”€ nodejs/
â”‚   â”œâ”€â”€ 01_install_selenium.md
â”‚   â”œâ”€â”€ 02_launch_browser.js
â”‚   â”œâ”€â”€ 03_options_headless.js
â”‚   â”œâ”€â”€ 04_block_resources_cdp.js
â”‚   â”œâ”€â”€ 05_navigation_and_locators.js
â”‚   â”œâ”€â”€ 06_shadow_dom.js
â”‚   â”œâ”€â”€ 07_data_extraction.js
â”‚   â”œâ”€â”€ 08_tables_and_export.js
â”‚   â”œâ”€â”€ 09_waits_and_retry.js
â”‚   â”œâ”€â”€ 10_downloads_and_monitoring.js
â”‚   â””â”€â”€ 11_proxy_and_stealth.js
â”‚
â””â”€â”€ README.md
```

## Python Selenium Examples

All examples use **selenium 4+**:

- `02_driver_initialization.py` â€” Chrome/Firefox/Edge/Safari drivers  
- `03_context_manager.py` â€” auto-quit with context manager  
- `04_options_headless.py` â€” headless mode, window size, user-agent  
- `05_prefs_and_cdp.py` â€” prefs and CDP commands  
- `06_navigation.py` â€” get, refresh, back, forward  
- `07_locators_and_find.py` â€” By API, find_element(s)  
- `08_shadow_dom.py` â€” accessing shadow root  
- `09_data_extraction.py` â€” element.text normalization, get_attribute  
- `10_lists_and_tables.py` â€” scrape lists and tables  
- `11_export_csv_json.py` â€” CSV/JSON export  
- `12_waits_and_sync.py` â€” implicit vs explicit waits  
- `13_stale_handling.py` â€” StaleElementReferenceException  
- `14_interactions.py` â€” clicks, send_keys, forms  
- `15_scrolling.py` â€” scrollIntoView, infinite scroll  
- `16_tabs_frames_alerts.py` â€” tabs, iframes, alerts  
- `17_sessions_and_auth.py` â€” login and cookies  
- `18_downloads_and_monitoring.py` â€” auto-download, monitor completion  
- `19_debugging_and_logging.py` â€” screenshots, logs  
- `20_network_and_proxy.py` â€” CDP, Selenium Wire, proxies  
- `21_grid_examples.py` â€” Selenium Grid remote driver examples  
- `22_scrapy_integration.py` â€” scrapy-selenium integration  
- `23_hasdata_async_example.py` â€” async scraping example

---

## Node.js Selenium Examples

All examples use **selenium-webdriver**:

- `02_driver_initialization.js` â€” Chrome/Firefox drivers  
- `03_options_headless.js` â€” headless mode, options, window size  
- `04_block_resources_cdp.js` â€” CDP commands to block images/fonts  
- `05_navigation_and_locators.js` â€” get, click, locators  
- `06_shadow_dom.js` â€” access shadow DOM via JS execution  
- `07_data_extraction.js` â€” text, attributes extraction  
- `08_tables_and_export.js` â€” build CSV/JSON from scraped data  
- `09_waits_and_retry.js` â€” implicit/explicit waits and retry  
- `10_downloads_and_monitoring.js` â€” download handling  
- `11_proxy_and_stealth.js` â€” proxies, stealth patterns


## Disclaimer

These examples are for **educational purposes** only. Learn more about [the legality of web scraping](https://hasdata.com/blog/is-web-scraping-legal).


## Notes

* Use context managers in Python to avoid leftover browser processes.
* CDP features work best with Chrome/Chromium.
* For large-scale scraping, consider Selenium Grid or Scrapy integration.
* All code is ready-to-run: adapt snippets to your own scraping tasks.

## ğŸ“ More Resources

* Full tutorial: [The Complete Guide to Web Scraping with Selenium in Python](https://hasdata.com/blog/web-scraping-using-selenium-python)
* [Join the community on Discord](https://discord.com/invite/QeuPtWpkAt)

* [Star this repo if helpful â­](#)
